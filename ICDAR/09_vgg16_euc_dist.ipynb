{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Features, Names, and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_path =  \"../feature/ICDAR-feature/train_features_triplet_loss.npy\"\n",
    "train_names_path = \"../feature/ICDAR-feature/train_names.npy\"\n",
    "train_labels_path = \"../feature/ICDAR-feature/train_labels.npy\"\n",
    "\n",
    "test_features_path = \"../feature/ICDAR-feature/test_features_triplet_loss.npy\"\n",
    "test_names_path = \"../feature/ICDAR-feature/test_names.npy\"\n",
    "test_labels_path = \"../feature/ICDAR-feature/test_labels.npy\"\n",
    "\n",
    "validation_features_path = \"../feature/ICDAR-feature/validation_features_triplet_loss.npy\"\n",
    "validation_names_path = \"../feature/ICDAR-feature/validation_names.npy\"\n",
    "validation_labels_path = \"../feature/ICDAR-feature/validation_labels.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.load(train_features_path)\n",
    "train_names = np.load(train_names_path)\n",
    "train_labels = np.load(train_labels_path)\n",
    "\n",
    "test_features = np.load(test_features_path)\n",
    "test_names = np.load(test_names_path)\n",
    "test_labels = np.load(test_labels_path)\n",
    "\n",
    "validation_features = np.load(validation_features_path)\n",
    "validation_names = np.load(validation_names_path)\n",
    "validation_labels = np.load(validation_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features shape :  (857, 512)\n",
      "test_features shape :  (401, 512)\n",
      "validation_features shape :  (391, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_features shape : \", train_features.shape)\n",
    "print(\"test_features shape : \", test_features.shape)\n",
    "print(\"validation_features shape : \", validation_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Gallery dilakukan untuk setiap kelas / nama seperti \"001\", \"002\", \"003\", dst dengan cara mengambil data training positive dan mengambil mean / rata-rata dari data tersebut\n",
    "def create_feature_gallery(train_features, train_names, train_labels):\n",
    "    gallery_feature = []\n",
    "    gallery_name = []\n",
    "\n",
    "    unique_names = set(train_names.flatten())\n",
    "    sorted_names = sorted(unique_names)\n",
    "\n",
    "    for name in sorted_names:\n",
    "        # print(name)\n",
    "        # print(name)\n",
    "        name_features = []\n",
    "\n",
    "        for feature, feature_name, label in zip(train_features, train_names, train_labels):\n",
    "            # print(feature, feature_name, label)\n",
    "            if name in feature_name and label == 1:\n",
    "                name_features.append(feature)\n",
    "\n",
    "        if name_features:\n",
    "            # print(name_features)\n",
    "            average_feature = np.mean(name_features, axis=0)\n",
    "            gallery_feature.append(average_feature)\n",
    "            gallery_name.append(name)\n",
    "\n",
    "    return gallery_feature, gallery_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_features, gallery_names = create_feature_gallery(train_features, train_names, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_feature_path = \"../feature/ICDAR-feature/gallery_features.npy\"\n",
    "gallery_name_path = \"../feature/ICDAR-feature/gallery_names.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(gallery_feature_path, gallery_features)\n",
    "np.save(gallery_name_path, gallery_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_features = np.load(gallery_feature_path)\n",
    "gallery_names = np.load(gallery_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gallery features shape :  (64, 512)\n"
     ]
    }
   ],
   "source": [
    "gallery_features_array = np.array(gallery_features)\n",
    "print(\"gallery features shape : \", gallery_features_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(feature_vector1, feature_vector2):\n",
    "    return np.sqrt(np.sum((feature_vector1 - feature_vector2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_euclidean_distance(test_features, test_names, test_labels, gallery_features, gallery_names):\n",
    "    euclidean_distances = []\n",
    "    euclidean_names = []\n",
    "    euclidean_actual_labels = []\n",
    "\n",
    "    for gallery_feature, gallery_name in zip(gallery_features, gallery_names):\n",
    "        curr_euclid_name = gallery_name\n",
    "        curr_euclid_feature = []\n",
    "        curr_euclid_label = []\n",
    "        curr_euclid_dist = []\n",
    "        for feature, name, label in zip(test_features, test_names, test_labels):\n",
    "            if gallery_name in name:\n",
    "                curr_euclid_feature.append(feature)\n",
    "                curr_euclid_label.append(label)\n",
    "        \n",
    "        for feature in curr_euclid_feature:\n",
    "            distance = euclidean_distance(feature, gallery_feature)\n",
    "            curr_euclid_dist.append(distance)\n",
    "\n",
    "        euclidean_distances.append(curr_euclid_dist)\n",
    "        euclidean_names.append(curr_euclid_name)\n",
    "        euclidean_actual_labels.append(curr_euclid_label)\n",
    "        \n",
    "    return euclidean_distances, euclidean_names, euclidean_actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_euclidean_distances, test_euclidean_names, test_euclidean_actual_labels = find_euclidean_distance(test_features, test_names, test_labels, gallery_features, gallery_names)\n",
    "train_euclidean_distances, train_euclidean_names, train_euclidean_actual_labels = find_euclidean_distance(train_features, train_names, train_labels, gallery_features, gallery_names)\n",
    "validation_euclidean_distances, validation_euclidean_names, validation_euclidean_actual_labels = find_euclidean_distance(validation_features, validation_names, validation_labels, gallery_features, gallery_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Euclidean Distance to Positive and Negative for Future Use (If needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_euc_dist(euclidean_distances, euclidean_names, euclidean_actual_labels):\n",
    "    positive_distance = []\n",
    "    positive_name = []\n",
    "    positive_label = []\n",
    "    negative_distance = []\n",
    "    negative_name = []\n",
    "    negative_label = []\n",
    "\n",
    "    for euclidean_distance, euclidean_name, euclidean_actual_label in zip(euclidean_distances, euclidean_names, euclidean_actual_labels):\n",
    "        pos_dist = []\n",
    "        neg_dist = []\n",
    "        pos_lab = []\n",
    "        neg_lab = []\n",
    "        for distance, label in zip(euclidean_distance, euclidean_actual_label):\n",
    "            if label == 0:\n",
    "                neg_dist.append(distance)\n",
    "                neg_lab.append(label)\n",
    "            else:\n",
    "                pos_dist.append(distance)\n",
    "                pos_lab.append(label)\n",
    "\n",
    "        positive_distance.append(pos_dist)\n",
    "        positive_name.append(euclidean_name)\n",
    "        positive_label.append(pos_lab)\n",
    "\n",
    "        negative_distance.append(neg_dist)\n",
    "        negative_name.append(euclidean_name)\n",
    "        negative_label.append(neg_lab)\n",
    "        # print(euclidean_distance, euclidean_name, euclidean_actual_label)\n",
    "\n",
    "    return positive_distance, negative_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_dist, train_negative_dist = split_euc_dist(train_euclidean_distances, train_names, train_euclidean_actual_labels)\n",
    "test_positive_dist, test_negative_dist = split_euc_dist(test_euclidean_distances, test_names, test_euclidean_actual_labels)\n",
    "validation_positive_dist, validation_negative_dist = split_euc_dist(validation_euclidean_distances, validation_names, validation_euclidean_actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train total : 857\n",
      "  Train pos : 463\n",
      "  Train neg : 394\n",
      " Test total : 401\n",
      "   Test pos : 212\n",
      "   Test neg : 189\n",
      "  Val total : 391\n",
      "    Val pos : 212\n",
      "    Val neg : 179\n"
     ]
    }
   ],
   "source": [
    "flat_train_positive_dist = [item for sublist in train_positive_dist for item in sublist]\n",
    "flat_train_negative_dist = [item for sublist in train_negative_dist for item in sublist]\n",
    "flat_test_positive_dist = [item for sublist in test_positive_dist for item in sublist]\n",
    "flat_test_negative_dist = [item for sublist in test_negative_dist for item in sublist]\n",
    "flat_validation_positive_dist = [item for sublist in validation_positive_dist for item in sublist]\n",
    "flat_validation_negative_dist = [item for sublist in validation_negative_dist for item in sublist]\n",
    "\n",
    "print(f'Train total : {len(flat_train_positive_dist) + len(flat_train_negative_dist)}')\n",
    "print(f'  Train pos : {len(flat_train_positive_dist)}')\n",
    "print(f'  Train neg : {len(flat_train_negative_dist)}')\n",
    "print(f' Test total : {len(flat_test_positive_dist) + len(flat_test_negative_dist)}')\n",
    "print(f'   Test pos : {len(flat_test_positive_dist)}')\n",
    "print(f'   Test neg : {len(flat_test_negative_dist)}')\n",
    "print(f'  Val total : {len(flat_validation_positive_dist) + len(flat_validation_negative_dist)}')\n",
    "print(f'    Val pos : {len(flat_validation_positive_dist)}')\n",
    "print(f'    Val neg : {len(flat_validation_negative_dist)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the lists of distances\n",
    "flat_test_distances = [item for sublist in test_euclidean_distances for item in sublist]\n",
    "flat_train_distances = [item for sublist in train_euclidean_distances for item in sublist]\n",
    "flat_validation_distances = [item for sublist in validation_euclidean_distances for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(flat_train_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max(euclidean_distances):\n",
    "    min_distance = min(euclidean_distances)\n",
    "    max_distance = max(euclidean_distances)\n",
    "\n",
    "    return min_distance, max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.0, max: 0.0\n"
     ]
    }
   ],
   "source": [
    "min_val, max_val = get_min_max(flat_train_distances)\n",
    "print(f'min: {min_val}, max: {max_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_distance(euclidean_distances, min_val, max_val):\n",
    "    all_distance = []\n",
    "\n",
    "    for distance in euclidean_distances:\n",
    "        normalized_distance = (distance - min_val) / (max_val - min_val)\n",
    "\n",
    "        # in case test and train distances are beyond max of train\n",
    "        if normalized_distance > 1:\n",
    "            normalized_distance = 1\n",
    "        elif normalized_distance < 0:\n",
    "            normalized_distance = 0\n",
    "        \n",
    "        all_distance.append(normalized_distance)\n",
    "\n",
    "    return all_distance\n",
    "\n",
    "def reverse_normalized_distance(euclidean_distances, min_val, max_val):\n",
    "    reverse_distance = []\n",
    "    normalized_distances = normalize_distance(euclidean_distances, min_val, max_val)\n",
    "    for distance in normalized_distances:\n",
    "        distance = -distance\n",
    "        reverse_distance.append(distance)\n",
    "\n",
    "    return reverse_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_positive_distances = reverse_normalized_distance(positive_distance)\n",
    "# normalized_negative_distances = reverse_normalized_distance(negative_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Christianto\\AppData\\Local\\Temp\\ipykernel_10808\\1599287016.py:5: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  normalized_distance = (distance - min_val) / (max_val - min_val)\n"
     ]
    }
   ],
   "source": [
    "normalized_test_euclidean_distance = reverse_normalized_distance(flat_test_distances, min_val, max_val)\n",
    "normalized_train_euclidean_distance = reverse_normalized_distance(flat_train_distances, min_val, max_val)\n",
    "normalized_validation_euclidean_distance = reverse_normalized_distance(flat_validation_distances, min_val, max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "print(normalized_test_euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m flat_validation_labels \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m validation_euclidean_actual_labels \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate ROC curve\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m fpr_test, tpr_test, thresholds_test \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_test_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_test_euclidean_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_intermediate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m roc_auc_test \u001b[38;5;241m=\u001b[39m auc(fpr_test, tpr_test)\n\u001b[0;32m      9\u001b[0m fpr_train, tpr_train, thresholds_train \u001b[38;5;241m=\u001b[39m roc_curve(flat_train_labels, normalized_train_euclidean_distance, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Andreas Christianto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Andreas Christianto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1094\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    993\u001b[0m     {\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1003\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m ):\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1094\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Andreas Christianto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:809\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    807\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n\u001b[0;32m    808\u001b[0m assert_all_finite(y_true)\n\u001b[1;32m--> 809\u001b[0m \u001b[43massert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Filter out zero-weighted samples, as they should not impact the result\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Andreas Christianto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:202\u001b[0m, in \u001b[0;36massert_all_finite\u001b[1;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[0;32m    177\u001b[0m     X,\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    182\u001b[0m ):\n\u001b[0;32m    183\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        documentation.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andreas Christianto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andreas Christianto\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# Flatten the lists of labels\n",
    "flat_test_labels = [item for sublist in test_euclidean_actual_labels for item in sublist]\n",
    "flat_train_labels = [item for sublist in train_euclidean_actual_labels for item in sublist]\n",
    "flat_validation_labels = [item for sublist in validation_euclidean_actual_labels for item in sublist]\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(flat_test_labels, normalized_test_euclidean_distance, drop_intermediate=False)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(flat_train_labels, normalized_train_euclidean_distance, drop_intermediate=False)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "fpr_validation, tpr_validation, thresholds_validation = roc_curve(flat_validation_labels, normalized_validation_euclidean_distance, drop_intermediate=False)\n",
    "roc_auc_validation = auc(fpr_validation, tpr_validation)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.plot(fpr_train, tpr_train, color='darkseagreen', lw=2, label=f'Train AUC = {roc_auc_train:.5f}')\n",
    "plt.plot(fpr_validation, tpr_validation, color='steelblue', lw=2, label=f'Validation AUC = {roc_auc_validation:.5f}')\n",
    "plt.plot(fpr_test, tpr_test, color='peru', lw=2, label=f'Test AUC = {roc_auc_test:.5f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Euclidean Distance')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00471698 0.00943396 0.01415094 0.01886792 0.02358491\n",
      " 0.02830189 0.03301887 0.03773585 0.04245283 0.04716981 0.05188679\n",
      " 0.05660377 0.06132075 0.06603774 0.07075472 0.0754717  0.08018868\n",
      " 0.08490566 0.08962264 0.09433962 0.0990566  0.10377358 0.10849057\n",
      " 0.11320755 0.11792453 0.12264151 0.12735849 0.13207547 0.13679245\n",
      " 0.14150943 0.14622642 0.1509434  0.15566038 0.16037736 0.16509434\n",
      " 0.16981132 0.1745283  0.17924528 0.18396226 0.18867925 0.19339623\n",
      " 0.19811321 0.20283019 0.20754717 0.21226415 0.21698113 0.22169811\n",
      " 0.22641509 0.23113208 0.23584906 0.24056604 0.24528302 0.25\n",
      " 0.25471698 0.25943396 0.26415094 0.26886792 0.27358491 0.27830189\n",
      " 0.28301887 0.28773585 0.29245283 0.29716981 0.30188679 0.30660377\n",
      " 0.31132075 0.31603774 0.32075472 0.3254717  0.33018868 0.33490566\n",
      " 0.33962264 0.34433962 0.3490566  0.35377358 0.35849057 0.36320755\n",
      " 0.36792453 0.37264151 0.37735849 0.38207547 0.38679245 0.39150943\n",
      " 0.39622642 0.4009434  0.40566038 0.41037736 0.41509434 0.41981132\n",
      " 0.4245283  0.42924528 0.43396226 0.43867925 0.44339623 0.44811321\n",
      " 0.45283019 0.45754717 0.46226415 0.46698113 0.47169811 0.47641509\n",
      " 0.48113208 0.48584906 0.49056604 0.49528302 0.5        0.50471698\n",
      " 0.50943396 0.51415094 0.51886792 0.52358491 0.52830189 0.53301887\n",
      " 0.53773585 0.54245283 0.54716981 0.55188679 0.55660377 0.56132075\n",
      " 0.56603774 0.57075472 0.5754717  0.58018868 0.58490566 0.58962264\n",
      " 0.59433962 0.5990566  0.60377358 0.60849057 0.61320755 0.61792453\n",
      " 0.62264151 0.62735849 0.63207547 0.63679245 0.64150943 0.64622642\n",
      " 0.6509434  0.65566038 0.66037736 0.66509434 0.66981132 0.6745283\n",
      " 0.67924528 0.68396226 0.68867925 0.69339623 0.69339623 0.69811321\n",
      " 0.70283019 0.70754717 0.71226415 0.71698113 0.72169811 0.72641509\n",
      " 0.73113208 0.73584906 0.74056604 0.74528302 0.75       0.75471698\n",
      " 0.75943396 0.76415094 0.76886792 0.77358491 0.77830189 0.77830189\n",
      " 0.77830189 0.78301887 0.78773585 0.79245283 0.79716981 0.80188679\n",
      " 0.80188679 0.80660377 0.81132075 0.81603774 0.82075472 0.82075472\n",
      " 0.8254717  0.8254717  0.83018868 0.83490566 0.83490566 0.83962264\n",
      " 0.83962264 0.84433962 0.8490566  0.85377358 0.85377358 0.85849057\n",
      " 0.86320755 0.86320755 0.86792453 0.87264151 0.87735849 0.88207547\n",
      " 0.88207547 0.88679245 0.89150943 0.89150943 0.89622642 0.9009434\n",
      " 0.9009434  0.90566038 0.91037736 0.91509434 0.91509434 0.91509434\n",
      " 0.91509434 0.91981132 0.9245283  0.92924528 0.92924528 0.93396226\n",
      " 0.93396226 0.93396226 0.93396226 0.93867925 0.94339623 0.94339623\n",
      " 0.94811321 0.95283019 0.95283019 0.95283019 0.95283019 0.95754717\n",
      " 0.96226415 0.96226415 0.96226415 0.96226415 0.96698113 0.96698113\n",
      " 0.96698113 0.96698113 0.96698113 0.96698113 0.96698113 0.96698113\n",
      " 0.96698113 0.96698113 0.97169811 0.97169811 0.97169811 0.97641509\n",
      " 0.97641509 0.97641509 0.97641509 0.98113208 0.98113208 0.98113208\n",
      " 0.98113208 0.98113208 0.98113208 0.98113208 0.98584906 0.98584906\n",
      " 0.98584906 0.98584906 0.98584906 0.98584906 0.98584906 0.98584906\n",
      " 0.98584906 0.98584906 0.98584906 0.98584906 0.99056604 0.99056604\n",
      " 0.99056604 0.99056604 0.99056604 0.99056604 0.99056604 0.99056604\n",
      " 0.99056604 0.99056604 0.99056604 0.99528302 0.99528302 0.99528302\n",
      " 0.99528302 0.99528302 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(tpr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00529101 0.00529101\n",
      " 0.00529101 0.00529101 0.00529101 0.00529101 0.00529101 0.00529101\n",
      " 0.00529101 0.00529101 0.00529101 0.00529101 0.00529101 0.00529101\n",
      " 0.00529101 0.00529101 0.00529101 0.00529101 0.00529101 0.01058201\n",
      " 0.01587302 0.01587302 0.01587302 0.01587302 0.01587302 0.01587302\n",
      " 0.02116402 0.02116402 0.02116402 0.02116402 0.02116402 0.02645503\n",
      " 0.02645503 0.03174603 0.03174603 0.03174603 0.03703704 0.03703704\n",
      " 0.04232804 0.04232804 0.04232804 0.04232804 0.04761905 0.04761905\n",
      " 0.04761905 0.05291005 0.05291005 0.05291005 0.05291005 0.05291005\n",
      " 0.05820106 0.05820106 0.05820106 0.06349206 0.06349206 0.06349206\n",
      " 0.06878307 0.06878307 0.06878307 0.06878307 0.07407407 0.07936508\n",
      " 0.08465608 0.08465608 0.08465608 0.08465608 0.08994709 0.08994709\n",
      " 0.0952381  0.1005291  0.10582011 0.10582011 0.10582011 0.11111111\n",
      " 0.11111111 0.11111111 0.11640212 0.12169312 0.12698413 0.12698413\n",
      " 0.12698413 0.13227513 0.13756614 0.14285714 0.14285714 0.14814815\n",
      " 0.15343915 0.15873016 0.16402116 0.16931217 0.17460317 0.17989418\n",
      " 0.18518519 0.19047619 0.19047619 0.1957672  0.2010582  0.2010582\n",
      " 0.20634921 0.21164021 0.21693122 0.21693122 0.22222222 0.22751323\n",
      " 0.23280423 0.23809524 0.24338624 0.24867725 0.24867725 0.25396825\n",
      " 0.25925926 0.26455026 0.26984127 0.27513228 0.28042328 0.28571429\n",
      " 0.29100529 0.2962963  0.3015873  0.30687831 0.30687831 0.31216931\n",
      " 0.31746032 0.32275132 0.32804233 0.33333333 0.33862434 0.34391534\n",
      " 0.34920635 0.35449735 0.35978836 0.35978836 0.36507937 0.37037037\n",
      " 0.37566138 0.38095238 0.38095238 0.38624339 0.39153439 0.3968254\n",
      " 0.4021164  0.40740741 0.41269841 0.41798942 0.42328042 0.42857143\n",
      " 0.43386243 0.43915344 0.44444444 0.44973545 0.45502646 0.46031746\n",
      " 0.46560847 0.47089947 0.47619048 0.48148148 0.48677249 0.49206349\n",
      " 0.4973545  0.5026455  0.50793651 0.51322751 0.51851852 0.52380952\n",
      " 0.52910053 0.53439153 0.53968254 0.54497354 0.55026455 0.55555556\n",
      " 0.56084656 0.56613757 0.57142857 0.57671958 0.58201058 0.58730159\n",
      " 0.59259259 0.5978836  0.6031746  0.60846561 0.61375661 0.61904762\n",
      " 0.62433862 0.62962963 0.63492063 0.64021164 0.64550265 0.65079365\n",
      " 0.65608466 0.66137566 0.66666667 0.67195767 0.67724868 0.68253968\n",
      " 0.68783069 0.69312169 0.6984127  0.7037037  0.70899471 0.71428571\n",
      " 0.71957672 0.72486772 0.73015873 0.73544974 0.74074074 0.74603175\n",
      " 0.75132275 0.75661376 0.76190476 0.76719577 0.77248677 0.77777778\n",
      " 0.78306878 0.78835979 0.79365079 0.7989418  0.8042328  0.80952381\n",
      " 0.81481481 0.82010582 0.82539683 0.83068783 0.83597884 0.84126984\n",
      " 0.84656085 0.85185185 0.85714286 0.86243386 0.86772487 0.87301587\n",
      " 0.87830688 0.88359788 0.88888889 0.89417989 0.8994709  0.9047619\n",
      " 0.91005291 0.91534392 0.92063492 0.92592593 0.93121693 0.93650794\n",
      " 0.94179894 0.94708995 0.95238095 0.95767196 0.96296296 0.96825397\n",
      " 0.97354497 0.97883598 0.98412698 0.98941799 0.99470899 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(fpr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tpr_at_fpr(fpr, tpr, target_fpr):\n",
    "    return np.interp(target_fpr, fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fprs = [0.1, 0.01, 0.001]\n",
    "tpr_at_target_fpr_train = [find_tpr_at_fpr(fpr_train, tpr_train, fpr) for fpr in target_fprs]\n",
    "tpr_at_target_fpr_test = [find_tpr_at_fpr(fpr_test, tpr_test, fpr) for fpr in target_fprs]\n",
    "tpr_at_target_fpr_val = [find_tpr_at_fpr(fpr_validation, tpr_validation, fpr) for fpr in target_fprs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "TPR at FPR 0.100: 0.981\n",
      "TPR at FPR 0.010: 0.808\n",
      "TPR at FPR 0.001: 0.678\n",
      "             AUC: 0.9887678021291292\n",
      "Validation\n",
      "TPR at FPR 0.100: 0.873\n",
      "TPR at FPR 0.010: 0.533\n",
      "TPR at FPR 0.001: 0.340\n",
      "             AUC: 0.95385791082534\n",
      "Test\n",
      "TPR at FPR 0.100: 0.934\n",
      "TPR at FPR 0.010: 0.778\n",
      "TPR at FPR 0.001: 0.693\n",
      "             AUC: 0.9794848757112908\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "for tpr, fpr in zip(tpr_at_target_fpr_train, target_fprs):\n",
    "    print(f'TPR at FPR {fpr:.3f}: {tpr:.3f}')\n",
    "print(f'             AUC: {roc_auc_train}')\n",
    "\n",
    "print(\"Validation\")\n",
    "for tpr, fpr in zip(tpr_at_target_fpr_val, target_fprs):\n",
    "    print(f'TPR at FPR {fpr:.3f}: {tpr:.3f}')\n",
    "print(f'             AUC: {roc_auc_validation}')\n",
    "\n",
    "print(\"Test\")\n",
    "for tpr, fpr in zip(tpr_at_target_fpr_test, target_fprs):\n",
    "    print(f'TPR at FPR {fpr:.3f}: {tpr:.3f}')\n",
    "print(f'             AUC: {roc_auc_test}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
