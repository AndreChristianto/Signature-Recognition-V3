{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train, Test, and Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_path =  \"../feature/BENGALI-feature/train_features.npy\"\n",
    "train_names_path = \"../feature/BENGALI-feature/train_names.npy\"\n",
    "train_labels_path = \"../feature/BENGALI-feature/train_labels.npy\"\n",
    "\n",
    "test_features_path = \"../feature/BENGALI-feature/test_features.npy\"\n",
    "test_names_path = \"../feature/BENGALI-feature/test_names.npy\"\n",
    "test_labels_path = \"../feature/BENGALI-feature/test_labels.npy\"\n",
    "\n",
    "validation_features_path = \"../feature/BENGALI-feature/validation_features.npy\"\n",
    "validation_names_path = \"../feature/BENGALI-feature/validation_names.npy\"\n",
    "validation_labels_path = \"../feature/BENGALI-feature/validation_labels.npy\"\n",
    "\n",
    "gallery_feature_path = \"../feature/BENGALI-feature/gallery_features.npy\"\n",
    "gallery_name_path = \"../feature/BENGALI-feature/gallery_names.npy\"\n",
    "\n",
    "train_features = np.load(train_features_path)\n",
    "train_names = np.load(train_names_path)\n",
    "train_labels = np.load(train_labels_path)\n",
    "\n",
    "test_features = np.load(test_features_path)\n",
    "test_names = np.load(test_names_path)\n",
    "test_labels = np.load(test_labels_path)\n",
    "\n",
    "validation_features = np.load(validation_features_path)\n",
    "validation_names = np.load(validation_names_path)\n",
    "validation_labels = np.load(validation_labels_path)\n",
    "\n",
    "gallery_features = np.load(gallery_feature_path)\n",
    "gallery_names = np.load(gallery_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 512)\n",
      "(3200,)\n",
      "(3200,)\n",
      "(1100, 512)\n",
      "(1100,)\n",
      "(1100,)\n",
      "(1100, 512)\n",
      "(1100,)\n",
      "(1100,)\n",
      "(100, 512)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_names.shape)\n",
    "print(test_features.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_names.shape)\n",
    "print(validation_features.shape)\n",
    "print(validation_labels.shape)\n",
    "print(validation_names.shape)\n",
    "print(gallery_features.shape)\n",
    "print(gallery_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = set(train_names.flatten())\n",
    "sorted_names = sorted(unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064', '065', '066', '067', '068', '069', '070', '071', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '084', '085', '086', '087', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099', '100']\n"
     ]
    }
   ],
   "source": [
    "print(sorted_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001' '002' '003' '004' '005' '006' '007' '008' '009' '010' '011' '012'\n",
      " '013' '014' '015' '016' '017' '018' '019' '020' '021' '022' '023' '024'\n",
      " '025' '026' '027' '028' '029' '030' '031' '032' '033' '034' '035' '036'\n",
      " '037' '038' '039' '040' '041' '042' '043' '044' '045' '046' '047' '048'\n",
      " '049' '050' '051' '052' '053' '054' '055' '056' '057' '058' '059' '060'\n",
      " '061' '062' '063' '064' '065' '066' '067' '068' '069' '070' '071' '072'\n",
      " '073' '074' '075' '076' '077' '078' '079' '080' '081' '082' '083' '084'\n",
      " '085' '086' '087' '088' '089' '090' '091' '092' '093' '094' '095' '096'\n",
      " '097' '098' '099' '100']\n"
     ]
    }
   ],
   "source": [
    "print(gallery_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triplets(unique_names, gallery_features, features, labels):\n",
    "    anchors, positives, negatives = [], [], []\n",
    "    for name, gallery in zip(unique_names, gallery_features):\n",
    "        # find all the instances for name\n",
    "        indices = np.where(train_names == name)[0]\n",
    "        # print(indices)\n",
    "        \n",
    "        # separate instances to positive and negative\n",
    "        positive_set, negative_set = [], []\n",
    "        for index in indices:\n",
    "            # print(index)\n",
    "            if labels[index] == 0:\n",
    "                negative_set.append(features[index])\n",
    "                # print(features[index])\n",
    "            else:\n",
    "                positive_set.append(features[index]) \n",
    "\n",
    "        negative_set = np.array(negative_set)\n",
    "        positive_set = np.array(positive_set)\n",
    "\n",
    "        # use feature gallery for anchor\n",
    "        # print(gallery.size)\n",
    "        anchor = gallery\n",
    "        \n",
    "        # print(positive_set.size)\n",
    "        # print(negative_set.size)\n",
    "\n",
    "        # randomize data picks to accomodate for unequal data size (total size is based on negative data size due to it being bigger than positive data size)\n",
    "        positive_idx = np.random.choice(len(positive_set), size=len(negative_set), replace=True)\n",
    "        positive = positive_set[positive_idx]\n",
    "        \n",
    "        anchor_set = []\n",
    "        for _ in range(0, len(negative_set)):\n",
    "            anchor_set.append(anchor)\n",
    "\n",
    "        anchors.append(anchor_set)\n",
    "        positives.append(positive)\n",
    "        negatives.append(negative_set)\n",
    "        print(len(anchors))\n",
    "        print(len(positives))\n",
    "        print(len(negatives))\n",
    "\n",
    "    anchors = np.concatenate(anchors, axis=0)\n",
    "    \n",
    "    positives = np.concatenate(positives, axis=0)\n",
    "\n",
    "    negatives = np.concatenate(negatives, axis=0)\n",
    "    \n",
    "    return anchors, positives, negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "17\n",
      "18\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "23\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "26\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "28\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "31\n",
      "31\n",
      "31\n",
      "32\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "36\n",
      "36\n",
      "36\n",
      "37\n",
      "37\n",
      "37\n",
      "38\n",
      "38\n",
      "38\n",
      "39\n",
      "39\n",
      "39\n",
      "40\n",
      "40\n",
      "40\n",
      "41\n",
      "41\n",
      "41\n",
      "42\n",
      "42\n",
      "42\n",
      "43\n",
      "43\n",
      "43\n",
      "44\n",
      "44\n",
      "44\n",
      "45\n",
      "45\n",
      "45\n",
      "46\n",
      "46\n",
      "46\n",
      "47\n",
      "47\n",
      "47\n",
      "48\n",
      "48\n",
      "48\n",
      "49\n",
      "49\n",
      "49\n",
      "50\n",
      "50\n",
      "50\n",
      "51\n",
      "51\n",
      "51\n",
      "52\n",
      "52\n",
      "52\n",
      "53\n",
      "53\n",
      "53\n",
      "54\n",
      "54\n",
      "54\n",
      "55\n",
      "55\n",
      "55\n",
      "56\n",
      "56\n",
      "56\n",
      "57\n",
      "57\n",
      "57\n",
      "58\n",
      "58\n",
      "58\n",
      "59\n",
      "59\n",
      "59\n",
      "60\n",
      "60\n",
      "60\n",
      "61\n",
      "61\n",
      "61\n",
      "62\n",
      "62\n",
      "62\n",
      "63\n",
      "63\n",
      "63\n",
      "64\n",
      "64\n",
      "64\n",
      "65\n",
      "65\n",
      "65\n",
      "66\n",
      "66\n",
      "66\n",
      "67\n",
      "67\n",
      "67\n",
      "68\n",
      "68\n",
      "68\n",
      "69\n",
      "69\n",
      "69\n",
      "70\n",
      "70\n",
      "70\n",
      "71\n",
      "71\n",
      "71\n",
      "72\n",
      "72\n",
      "72\n",
      "73\n",
      "73\n",
      "73\n",
      "74\n",
      "74\n",
      "74\n",
      "75\n",
      "75\n",
      "75\n",
      "76\n",
      "76\n",
      "76\n",
      "77\n",
      "77\n",
      "77\n",
      "78\n",
      "78\n",
      "78\n",
      "79\n",
      "79\n",
      "79\n",
      "80\n",
      "80\n",
      "80\n",
      "81\n",
      "81\n",
      "81\n",
      "82\n",
      "82\n",
      "82\n",
      "83\n",
      "83\n",
      "83\n",
      "84\n",
      "84\n",
      "84\n",
      "85\n",
      "85\n",
      "85\n",
      "86\n",
      "86\n",
      "86\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "90\n",
      "90\n",
      "90\n",
      "91\n",
      "91\n",
      "91\n",
      "92\n",
      "92\n",
      "92\n",
      "93\n",
      "93\n",
      "93\n",
      "94\n",
      "94\n",
      "94\n",
      "95\n",
      "95\n",
      "95\n",
      "96\n",
      "96\n",
      "96\n",
      "97\n",
      "97\n",
      "97\n",
      "98\n",
      "98\n",
      "98\n",
      "99\n",
      "99\n",
      "99\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "anchors, positives, negatives = create_triplets(sorted_names, gallery_features, train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n"
     ]
    }
   ],
   "source": [
    "print(len(anchors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = []\n",
    "for anchor, positive, negative in zip(anchors, positives, negatives):\n",
    "    triplets.append((anchor, positive, negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triplet_loss_model(input_shape):\n",
    "    anchor_input = layers.Input(shape=input_shape, name='anchor_input')\n",
    "    positive_input = layers.Input(shape=input_shape, name='positive_input')\n",
    "    negative_input = layers.Input(shape=input_shape, name='negative_input')\n",
    "\n",
    "    # Triplet loss function\n",
    "    margin = 0.2\n",
    "    positive_distance = tf.reduce_sum(tf.square(anchor_input - positive_input), axis=1)\n",
    "    negative_distance = tf.reduce_sum(tf.square(anchor_input - negative_input), axis=1)\n",
    "    loss = tf.maximum(0.0, positive_distance - negative_distance + margin)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    triplet_loss_model = models.Model(inputs=[anchor_input, positive_input, negative_input], outputs=loss)\n",
    "    return triplet_loss_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (train_features.shape[1],)\n",
    "triplet_model = create_triplet_loss_model(input_shape)\n",
    "triplet_model.compile(optimizer='adam', loss=lambda y_true, y_pred: y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " anchor_input (InputLayer)   [(None, 512)]                0         []                            \n",
      "                                                                                                  \n",
      " positive_input (InputLayer  [(None, 512)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " negative_input (InputLayer  [(None, 512)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_12 (TFOpL  (None, 512)                  0         ['anchor_input[0][0]',        \n",
      " ambda)                                                              'positive_input[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_13 (TFOpL  (None, 512)                  0         ['anchor_input[0][0]',        \n",
      " ambda)                                                              'negative_input[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.square_8 (TFOpLamb  (None, 512)                  0         ['tf.math.subtract_12[0][0]'] \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square_9 (TFOpLamb  (None, 512)                  0         ['tf.math.subtract_13[0][0]'] \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_8 (TFOp  (None,)                      0         ['tf.math.square_8[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_9 (TFOp  (None,)                      0         ['tf.math.square_9[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.subtract_14 (TFOpL  (None,)                      0         ['tf.math.reduce_sum_8[0][0]',\n",
      " ambda)                                                              'tf.math.reduce_sum_9[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None,)                      0         ['tf.math.subtract_14[0][0]'] \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.math.maximum_4 (TFOpLam  (None,)                      0         ['tf.__operators__.add_4[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_4 (TFO  ()                           0         ['tf.math.maximum_4[0][0]']   \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 426880 (1.63 MB)\n",
      "Trainable params: 426880 (1.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Andreas Christianto\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "57/57 [==============================] - 1s 3ms/step - loss: 3.3858\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.3858\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.3858\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.3858\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.3858\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.3858\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.3858\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.3858\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.3858\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.3858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22a1b618210>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_model.fit([anchors, positives, negatives], np.zeros_like(anchors), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = embedding_model.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value 1 is not present in train_embeddings.\n"
     ]
    }
   ],
   "source": [
    "if np.any(train_embeddings == 1):\n",
    "    print(\"The value 1 is present in train_embeddings.\")\n",
    "else:\n",
    "    print(\"The value 1 is not present in train_embeddings.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
